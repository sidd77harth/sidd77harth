from sklearn.datasets import load_boston import pandas as pd
import matplotlib.pyplot as plt import seaborn as sns
import numpy as np
 
from statsmodels.stats.outliers_influence import variance_inflation_factor as vif from sklearn.decomposition import PCA
from sklearn.preprocessing import RobustScaler from sklearn.preprocessing import MinMaxScaler from sklearn.model_selection import train_test_split import tensorflow as tf
from tensorflow.keras import Sequential from tensorflow.keras.layers import Dense #load the dataset
data = load_boston()

df = pd.DataFrame(data.data, columns=data.feature_names) df[“Price”] = data.target
#check for null values df.isnull().sum()
def create_vif(dataframe): #create an empty dataframe vif_table = pd.DataFrame()
#populate the first column with the columns of the dataset vif_table[“variables”] = dataframe.columns
#calculate the VIF of each column and create a VIF column to store the number vif_table[“VIF”] = [vif(dataframe.values, i) for i in range(df.shape[1])]
return vif_table

#print the VIF table for each variable print(create_vif(df))


pca = PCA(n_components=1)

df[“new”] = pca.fit_transform(df[[“DIS”, “RAD”, “INDUS”]]) #drop the three columns from the dataset
df = df.drop([”DIS”, ”RAD”, ”INDUS”], axis=1) print(create_vif(df))
pp = sns.pairplot(df[[”NOX”, ”RM”, ”TAX”, ”LSTAT”, ”new”]]) pp = pp.map_lower(sns.regplot)
pp = pp.map_upper(sns.kdeplot); df1 = df.copy()
# # Create a figure with 10 subplots with a width spacing of 1.5 fig, ax = plt.subplots(2,5)
 
fig.subplots_adjust(wspace=1.5)
# Create a boxplot for the continuous features
box_plot1 = sns.boxplot(y=np.log(df1[df1.columns[0]]), ax=ax[0][0]) box_plot2 = sns.boxplot(y=np.log(df1[df1.columns[1]]), ax=ax[0][1]) box_plot3 = sns.boxplot(y=np.log(df1[df1.columns[2]]), ax=ax[0][2]) box_plot4 = sns.boxplot(y=np.log(df1[df1.columns[3]]), ax=ax[0][3]) box_plot5 = sns.boxplot(y=np.log(df1[df1.columns[4]]), ax=ax[0][4]) box_plot6 = sns.boxplot(y=np.log(df1[df1.columns[5]]), ax=ax[1][0]) box_plot7 = sns.boxplot(y=np.log(df1[df1.columns[6]]), ax=ax[1][1]) box_plot8 = sns.boxplot(y=np.log(df1[df1.columns[-3]]), ax=ax[1][2]) box_plot9 = sns.boxplot(y=np.log(df1[df1.columns[8]]), ax=ax[1][3]) box_plot10 = sns.boxplot(y=np.log(df1[df1.columns[10]]), ax=ax[1][4])

#One-Hot Encode the CHAS column
df = pd.get_dummies(df, columns=[”CHAS”], drop_first=True) #define the features and the labels, X and y
X = df.drop([”Price”], axis=1) y = df[”Price”]

#split the features and labels into train and test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

#rescale the data to be robust to outliers scaler = RobustScaler() scaler.fit(X_train)
X_train = scaler.transform(X_train) X_test = scaler.transform(X_test)

model = Sequential()
model.add(Dense(15, input_dim=11, activation=”relu”)) model.add(Dense(1, activation=”linear”))
model.compile(loss=”mse”, optimizer=”adam”, metrics=[”;mse”, ”mae”])” history = model.fit(X_train, y_train, epochs=200, validation_split=0.2) history_df = pd.DataFrame(history.history)
plt.plot(history_df[”loss”], label=”loss”) plt.plot(history_df[”val_loss”], label=”val_loss”) plt.legend()
model.evaluate(X_test, y_test, batch_size=128) y_pred = model.predict(X_test).flatten()
 

a = plt.axes(aspect=“equal“) plt.scatter(y_test, y_pred) plt.xlabel(“True values“) plt.ylabel(“Predicted values“)
plt.title(“A plot that shows the true and predicted values“) plt.xlim([0, 60])
plt.ylim([0, 60])
plt.plot([0, 60], [0, 60])

model = Sequential()
model.add(Dense(15, input_dim=11, activation=&#39;relu&#39;)) model.add(Dense(7, activation=“relu“))
model.add(Dense(3, activation=“relu“)) model.add(Dense(1, activation=“linear“))
model.compile(loss=“mse“, optimizer=“adam“, metrics=[“mse“, “mae“]) #train the neural network on the train dataset
history = model.fit(X_train, y_train, epochs=200, validation_split=0.2)
model.evaluate(X_test, y_test, batch_size=128) a = plt.axes(aspect=“equal“)
plt.scatter(y_test, y_pred) plt.xlabel(“True values“) plt.ylabel(“Predicted values“)
plt.title(“A plot that shows the true and predicted values“) plt.xlim([0, 60])
plt.ylim([0, 60])
plt.plot([0, 60], [0, 60])
